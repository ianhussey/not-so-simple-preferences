---
title: "(Not so) simple preferences"
subtitle: "Analysis"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- could we add analysis for participants 1:N and show how the multiverse changes with additional recruitment? or should we do this for only the default analysis? 
- another version of the function has additional forms of cohen's d with bootstrapping etc right? re-add them here.
- change "total_completion_check" to "total_completion_time_check" throughout


```{r include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

options(scipen=999)

```

```{r}

# Dependencies 
# N.B.: to ensure full computational reproducibility, R version 4.3.3 should be used. 

library(groundhog)

groundhog_day = "2024-04-07"

packages = c("effectsize","faux","janitor",
             "rstatix", "effsize",
             "psych", "MBESS", "lsr",
             "metafor", "esc", "esci",
             "dplyr", "tidyr", "tibble",
             "forcats", "ggplot2", "stringr")

groundhog.library(packages, groundhog_day)

```

# Functions

## Individual Cohen's d functions

```{r}

cohens_d_s_metafor <- function(data){
  # nb always applies hedges correction
  require(dplyr)
  require(tibble)
  require(metafor)
  
  data <- data |>
    select(id, stimulus, score)
  
  summaries <- data |>
    group_by(stimulus) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n()) |>
    pivot_wider(names_from = "stimulus", 
                values_from = c("mean", "sd", "n"))
  
  fit <- escalc(measure = "SMD", 
                m1i = mean_stimulus2, 
                sd1i = sd_stimulus2, 
                n1i = n_stimulus2,
                m2i = mean_stimulus1, 
                sd2i = sd_stimulus1, 
                n2i = n_stimulus1, 
                data = summaries, 
                append = FALSE)
  
  res <- 
    tibble(estimate = fit$yi,
           ci_lower = fit$yi - sqrt(fit$vi)*1.96,
           ci_upper = fit$yi + sqrt(fit$vi)*1.96)
  return(res)
}


cohens_d_s_esc <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esc)
  
  summaries <- data |>
    group_by(stimulus) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  fit <- esc::esc_mean_sd(grp1m  = summaries$mean[summaries$stimulus == "stimulus2"],
                          grp1sd = summaries$sd[summaries$stimulus == "stimulus2"],
                          grp1n  = summaries$n[summaries$stimulus == "stimulus2"],
                          grp2m  = summaries$mean[summaries$stimulus == "stimulus1"],
                          grp2sd = summaries$sd[summaries$stimulus == "stimulus1"],
                          grp2n  = summaries$n[summaries$stimulus == "stimulus1"],
                          es.type = ifelse(hedges_correction, "g", "d"))
  
  res <- 
    tibble(estimate = fit$es,
           ci_lower = fit$ci.lo,
           ci_upper = fit$ci.hi)
  
  return(res)
}


cohens_d_z_esc <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esc)
  
  data <- data |>
    select(id, stimulus, score)
  
  summaries <- data |>
    group_by(stimulus) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  r <- data |>
    pivot_wider(names_from = "stimulus",
                values_from = "score") |>
    dplyr::select(-id) |>
    cor_test()
  
  fit <- esc::esc_mean_sd(grp1m  = summaries$mean[summaries$stimulus == "stimulus2"],
                          grp1sd = summaries$sd[summaries$stimulus == "stimulus2"],
                          grp1n  = summaries$n[summaries$stimulus == "stimulus2"],
                          grp2m  = summaries$mean[summaries$stimulus == "stimulus1"],
                          grp2sd = summaries$sd[summaries$stimulus == "stimulus1"],
                          grp2n  = summaries$n[summaries$stimulus == "stimulus1"],
                          r = r$cor,
                          es.type = ifelse(hedges_correction, "g", "d"))
  
  res <- 
    tibble(estimate = fit$es,
           ci_lower = fit$ci.lo,
           ci_upper = fit$ci.hi)
  
  return(res)
}


cohens_d_s_rstatix <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(rstatix)
  
  fit <- rstatix::cohens_d(formula = score ~ stimulus,
                           data = data,
                           comparisons = list(c("stimulus1", "stimulus2")),
                           ref.group = "stimulus2",
                           paired = FALSE,
                           hedges.correction = hedges_correction,
                           ci = TRUE,
                           ci.type = "bca",
                           nboot = 2000)
  
  res <- 
    tibble(estimate = fit$effsize,
           ci_lower = fit$conf.low,
           ci_upper = fit$conf.high)
  
  return(res)
}


cohens_d_z_rstatix <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(rstatix)
  
  fit <- rstatix::cohens_d(formula = score ~ stimulus,
                           data = data,
                           comparisons = list(c("stimulus1", "stimulus2")),
                           ref.group = "stimulus2",
                           paired = TRUE,
                           hedges.correction = hedges_correction,
                           ci = TRUE,
                           ci.type = "bca",
                           nboot = 2000)
  
  res <- 
    tibble(estimate = fit$effsize,
           ci_lower = fit$conf.low,
           ci_upper = fit$conf.high)
  
  return(res)
}


# esci used to have a within subjects d in 2020 but now doesn't? and its not in the git history
cohens_d_s_esci <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(esci)
  
  summaries <- data |>
    group_by(stimulus) |>
    summarize(mean = mean(score),
              sd = sd(score),
              n = n())
  
  fit <- esci::CI_smd_ind_contrast(means = summaries$mean,
                                   sds = summaries$sd,
                                   ns = summaries$n,
                                   contrast = c(+1, -1),
                                   conf_level = 0.95,
                                   assume_equal_variance = FALSE,
                                   correct_bias = hedges_correction)
  
  res <- 
    tibble(estimate = fit$effect_size,
           ci_lower = fit$LL,
           ci_upper = fit$UL)
  
  return(res)
}


cohens_d_s_effsize <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(effsize)
  
  fit <- effsize::cohen.d(score ~ stimulus, 
                          paired = FALSE,
                          pooled = TRUE,
                          hedges.correction = hedges_correction,
                          data = data)
  
  res <- 
    tibble(estimate = fit$estimate,
           ci_lower = fit$conf.int[1],
           ci_upper = fit$conf.int[2])
  
  return(res)
}


cohens_d_dep_effsize <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(effsize)
  
  fit <- effsize::cohen.d(score ~ stimulus | Subject(id), 
                          paired = TRUE,
                          pooled = TRUE,
                          hedges.correction = hedges_correction,
                          data = data)
  
  res <- 
    tibble(estimate = fit$estimate,
           ci_lower = fit$conf.int[1],
           ci_upper = fit$conf.int[2])
  
  return(res)
}


cohens_d_s_psych <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(tibble)
  require(psych)
  
  fit <- psych::cohen.d(score ~ stimulus,
                        data = data) 
  
  res <- 
    tibble(estimate = ifelse(hedges_correction, fit$hedges.g[2]*-1, fit$cohen.d[2]*-1),
           ci_lower = ifelse(hedges_correction, min(fit$hedges.g*-1), min(fit$cohen.d*-1)),
           ci_upper = ifelse(hedges_correction, max(fit$hedges.g*-1), max(fit$cohen.d*-1)))
  
  return(res)
}



cohens_d_s_mbess <- function(data, hedges_correction = TRUE){
  require(dplyr)
  require(MBESS)
  
  d <- MBESS::smd(Group.1 = data |> filter(stimulus == "stimulus2") |> pull(score), 
                  Group.2 = data |> filter(stimulus == "stimulus1") |> pull(score),
                  Unbiased = hedges_correction)
  
  t <- t.test(score ~ stimulus, data = data)$statistic
  
  cis <- ci.smd(ncp = t,
                #smd = d, 
                n.1 = data |> filter(stimulus == "stimulus2") |> pull(score) |> length(), 
                n.2 = data |> filter(stimulus == "stimulus1") |> pull(score) |> length())
  
  res <- 
    data.frame(estimate = cis$smd,
               ci_lower = cis$Lower.Conf.Limit.smd,
               ci_upper = cis$Upper.Conf.Limit.smd) 
  
  return(res)
}


cohens_d_s_lsr <- function(data){
  require(dplyr)
  require(tibble)
  require(lsr)
  
  # note that lsr::cohenD returns the absolute value of cohen's d, ie always positive values. fix this here to bring it in line with other packages' functions.
  mean_stimulus1 <- data |> dplyr::filter(stimulus == "stimulus1") |> summarize(mean = mean(score))
  mean_stimulus2 <- data |> dplyr::filter(stimulus == "stimulus2") |> summarize(mean = mean(score))
  
  d <- lsr::cohensD(score ~ stimulus,
                    data = data) 
  
  res <- 
    tibble(estimate = as.numeric(ifelse(mean_stimulus1 < mean_stimulus2, d, d * -1)),
           ci_lower = NA,
           ci_upper = NA) 
  
  return(res)
}


cohens_d_dep_lsr <- function(data){
  require(dplyr)
  require(tibble)
  require(lsr)
  
  # note that lsr::cohenD returns the absolute value of cohen's d, ie always positive values. fix this here to bring it in line with other packages' functions.
  mean_stimulus1 <- data |> dplyr::filter(stimulus == "stimulus1") |> summarize(mean = mean(score))
  mean_stimulus2 <- data |> dplyr::filter(stimulus == "stimulus2") |> summarize(mean = mean(score))
  
  d <- lsr::cohensD(data |> dplyr::filter(stimulus == "stimulus1") |> pull(score),
                    data |> dplyr::filter(stimulus == "stimulus2") |> pull(score),
                    method = "paired") 
  
  res <- 
    tibble(estimate = as.numeric(ifelse(mean_stimulus1 < mean_stimulus2, d, d * -1)),
           ci_lower = NA,
           ci_upper = NA) 
  
  return(res)
}


# assumes that 'data' contains columns named score (numeric) and stimulus (factor with two levels, stimulus1 and stimulus2, where positive cohen's d means higher scores at stimulus2)
# assumes a two sided Student's t test with alpha = .05
# by default, assumes correlation between stimuluss is 0. larger values will narrow the CIs but leave the estimate unchanged. so, default result is the worst case stimulus1cision.
d_t_dependent <- function(data, hedges_correction = TRUE, r = 0) { # assumes a correlation of 0 for simplicity
  require(dplyr)
  
  fit <- t.test(data$score[data$stimulus == "stimulus2"],
                data$score[data$stimulus == "stimulus1"], 
                paired = TRUE)
  
  res <- 
    data.frame(t_stat = fit$statistic["t"],
               df = fit$parameter["df"],
               r = r) |>
    mutate(n = df + 1, # for dependent t test, n = df + 1
           dt_estimate = t_stat / sqrt(n), # for dependent t test, d_t = t / sqrt(n)
           dt_estimate = ifelse(hedges_correction, 
                                dt_estimate * (1 - (3 / (4 * n - 9))),
                                dt_estimate),
           dt_se = sqrt((2 * (1 - r)) / n + (dt_estimate ^ 2) / (2 * n)), # default assumes a correlation of 0
           ci_lower = dt_estimate - (1.96 * dt_se),
           ci_upper = dt_estimate + (1.96 * dt_se),
           hedges_correction = hedges_correction) |>
    dplyr::select(hedges_correction, estimate = dt_estimate, ci_lower, ci_upper)
  
  return(res)
}


# cohen's d from a Student's t test (two sided, alpha = .05)
# if a Welches' t test, the conversion of df to N is imstimulus1cise, affecting the CIs.
# assumes that 'data' contains columns named score (numeric) and stimulus (factor with two levels)
d_t_independent <- function(data, hedges_correction = TRUE){
  require(dplyr)
  
  fit <- t.test(score ~ stimulus, 
                data = data,
                paired = FALSE, 
                var.equal = TRUE)
  
  res <- 
    data.frame(t_stat = fit$statistic["t"],
               df = fit$parameter["df"]) |>
    mutate(n1 = data |> filter(stimulus == "stimulus2") |> nrow(),
           n2 = data |> filter(stimulus == "stimulus1") |> nrow(),
           dt_estimate = t_stat * sqrt(1/n1 + 1/n2), # d = t * sqrt(1/n1 + 1/n2) - from lakens 2013 equation 2
           dt_estimate = ifelse(hedges_correction, 
                                dt_estimate * (1 - (3 / (4 * (n1+n2) - 9))),
                                dt_estimate),
           dt_se = sqrt((n1 + n2) / (n1 * n2) + (dt_estimate^2) / (2 * (n1 + n2 - 2))),
           ci_lower = dt_estimate - (1.96 * dt_se),
           ci_upper = dt_estimate + (1.96 * dt_se),
           hedges_correction = hedges_correction) |>
    dplyr::select(hedges_correction, estimate = dt_estimate, ci_lower, ci_upper)
  
  return(res)
}

```

## Multiverse analysis function

this is the most recent version of the multiple cohen's d analysis as of 27-05. it moves the `data <- data |> select(id, stimulus, score)` into the individual cohen's d functions.

```{r}

multiverse_analysis <- function(data, measure, check, hedges_correction = TRUE){
  
  # check if 'data' is a dataframe or tibble
  if (!is.data.frame(data) && !is_tibble(data)) {
    stop("The 'data' argument must be a dataframe or tibble.")
  }
  
  # check for 'score' column and its type
  if (!"score" %in% names(data) || !is.numeric(data$score)) {
    stop("The 'data' must contain a numeric column named 'score'.")
  }
  
  # check for 'stimulus' column, its type, and number of levels
  if (!"stimulus" %in% names(data)) {
    stop("The 'data' must contain a column named 'stimulus'.")
  }
  if (!is.factor(data$stimulus) && !is.character(data$stimulus)) {
    stop("The 'stimulus' column must be of type factor or character.")
  }
  
  # check that 'stimulus' has exactly two levels
  if (nlevels(data$stimulus) != 2) {
    stop("The 'stimulus' column must have exactly two levels.")
  }
  
  data <- data |>
    # convert 'stimulus' to factor if it's not already
    mutate(stimulus == as.factor(stimulus)) |>
    # use only the specified measure
    filter(measure == measure) |>
    # define check and exclude
    rename(check = {{check}}) |>
    filter(check == "passed")
  
  results <- 
    bind_rows(
      effectsize::cohens_d(score ~ stimulus, data = data, pooled_sd = TRUE, adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Hedges_g, ci_lower = CI_low, ci_upper = CI_high),
      
      cohens_d_s_psych(data = data, hedges_correction = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s",
               implementation = "{psych}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_mbess(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{MBESS}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_effsize(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{effsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_rstatix(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{rstatix}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_metafor(data = data) |> 
        mutate(type = "d_s",
               implementation = "{metafor}",
               hedges_correction = TRUE) |> # nb always applies hedges correction
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_z_rstatix(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_z",
               implementation = "{rstatix}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_esc(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_s",
               implementation = "{esc}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # cohens_d_z_esc(data = data, hedges_correction = hedges_correction) |>   # TODO error: Values from `score` are not uniquely identified
      #   mutate(type = "d_??? (dep)",
      #          implementation = "{esc}",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_esci(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (indep)",
               implementation = "{esci}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_dep_effsize(data = data, hedges_correction = hedges_correction) |> 
        mutate(type = "d_??? (dep)",
               implementation = "{effsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_s_lsr(data = data) |> 
        mutate(type = "d_s",
               implementation = "{lsr}",
               hedges_correction = FALSE) |> # lsr doesn't have an option for hedges corrections
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      cohens_d_dep_lsr(data = data) |> 
        mutate(type = "d_z",
               implementation = "{lsr}",
               hedges_correction = FALSE) |> # lsr doesn't have an option for hedges corrections
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # this provides nearly identical results to d_s under most conditions
      # effectsize::cohens_d(score ~ stimulus, data = data, pooled_sd = FALSE, adjust = hedges_correction) |>
      #   as_tibble() |>
      #   mutate(type = "d_s_nonpooled",
      #          implementation = "{effectsize}",
      #          hedges_correction = hedges_correction) |>
      #   dplyr::select(implementation, type, hedges_correction, estimate = Hedges_g, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ stimulus | id, data = data, method = "d", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_s_withinCIs",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Cohens_d, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ stimulus | id, data = data, method = "rm", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_rm",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_rm, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ stimulus | id, data = data, method = "av", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_av",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_av, ci_lower = CI_low, ci_upper = CI_high),
      
      effectsize::repeated_measures_d(score ~ stimulus | id, data = data, method = "b", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_b",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = Beckers_d, ci_lower = CI_low, ci_upper = CI_high),
      
      # use stimulus stimulus2's SD rather than stimulus1. 
      # this is useful to include as not all comparisons are stimulus1-stimulus2, some are the same participants rating stimulus X and Y, and either could be the reference
      data |>
        mutate(stimulus = fct_relevel(stimulus, "stimulus1", "stimulus2")) |>
        effectsize::repeated_measures_d(score ~ stimulus | id, data = _, method = "b", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_b (alt)",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction,
               estimate = Beckers_d * -1,
               ci_lower = CI_high * -1,
               ci_upper = CI_low * -1) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      effectsize::repeated_measures_d(score ~ stimulus | id, data = data, method = "z", adjust = hedges_correction) |> 
        as_tibble() |> 
        mutate(type = "d_z",
               implementation = "{effectsize}",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate = d_z, ci_lower = CI_low, ci_upper = CI_high),
      
      # this provides the same estimate as d_s
      d_t_independent(data = data, hedges_correction = hedges_correction) |>
        as_tibble() |>
        mutate(type = "d_t (independent)",
               implementation = "[custom]",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper),
      
      # this provides the same estimate as d_z with slightly wider CIs
      d_t_dependent(data = data, hedges_correction = hedges_correction) |>
        as_tibble() |>
        mutate(type = "d_t (dependent, r = 0)",
               implementation = "[custom]",
               hedges_correction = hedges_correction) |>
        dplyr::select(implementation, type, hedges_correction, estimate, ci_lower, ci_upper)
    )
  return(results)
}

```

```{r}


# plot_different_dependent_cohens_ds <- function(parameters){
#   data_for_simulations <- 
#     faux::rnorm_multi(n = parameters$simulation_n, 
#                       mu = c(stimulus1 = parameters$mean_stimulus1, stimulus2 = parameters$mean_stimulus2), 
#                       sd = c(parameters$sd_stimulus1, parameters$sd_stimulus2), 
#                       r = matrix(c(1, parameters$r_stimulus1_stimulus2, 
#                                    parameters$r_stimulus1_stimulus2, 1), 
#                                  ncol = 2)) |>
#     rownames_to_column(var = "id") |>
#     pivot_longer(cols = -id,
#                  names_to = "stimulus",
#                  values_to = "score") |>
#     mutate(stimulus = fct_relevel(stimulus, "stimulus2", "stimulus1")) # ensure that factor levels are the in the correct order, especially for d_b
#   
#   simulation_results <- data_for_simulations |>
#     multiple_cohens_ds_for_dependent_data() |>
#     select(-hedges_correction) |>
#     mutate(ci_width = ci_upper - ci_lower,
#            sig = ifelse((ci_lower > 0 & ci_upper > 0) |
#                           (ci_lower < 0 & ci_upper < 0) |
#                           (is.na(ci_lower) & is.na(ci_upper)), TRUE, FALSE))
#   
#   plot <- ggplot(simulation_results, aes(paste(type, implementation), estimate, color = sig)) + 
#     geom_hline(yintercept = 0, linetype = "dashed") +
#     geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), size = 0.8) +
#     geom_point(position = position_dodge(width = 0.5), size = 1.8) +
#     scale_y_continuous(breaks = scales::pretty_breaks()) +
#     coord_flip() +
#     theme_linedraw() +
#     xlab("") +
#     ylab("Cohen's d") +
#     scale_color_viridis_d(begin = 0.2, end = 0.5, option = "D") +
#     theme(legend.position = "none",
#           panel.grid.minor = element_blank())
#   
#   return(plot)
# }

```

# Simulate data

```{r}

library(faux)

dat_outcomes <- 
  # NB the below method only simulates correlations between the different DVs, not between the stimulus1 and stimulus 2 ratings,
  # so it implicitly sets the stimulus1-stimulus2 correlations to 0 in the population.
  full_join(
    sim_design(within = list(measure = c(original = 'original',
                                         new1 = 'refined scale 1 - based on loadings with single item desirability',
                                         new2 = 'refined scale 2 - based on main factor of original scale',
                                         classic = 'classic items used in evaluative learning studies',
                                         single = 'single item desirability')),
               between = list(condition = c(stimulus1 = 'stimulus1',
                                            stimulus2 = 'stimulus2')),
               n  = 100, 
               mu = 0.8, 
               sd = 1.0,
               r  = 0.80, 
               dv = "stimulus1",
               long = TRUE,
               plot = FALSE) |>
      mutate(id = as.factor(id)) |>
      arrange(id),
    sim_design(within = list(measure = c(original = 'original',
                                         new1 = 'refined scale 1 - based on loadings with single item desirability',
                                         new2 = 'refined scale 2 - based on main factor of original scale',
                                         classic = 'classic items used in evaluative learning studies',
                                         single = 'single item desirability')),
               between = list(condition = c(stimulus1 = 'stimulus1',
                                            stimulus2 = 'stimulus2')),
               n  = 100, 
               mu = 0.8, 
               sd = 1.0,
               r  = 0.80, 
               dv = "stimulus2",
               long = TRUE,
               plot = FALSE) |>
      mutate(id = as.factor(id)) |>
      arrange(id),
    by = c("id", "condition", "measure")
  ) |>
  # reshape
  pivot_longer(cols = c("stimulus1", "stimulus2"),
               names_to = "stimulus",
               values_to = "score") |>
  mutate(stimulus = fct_relevel(stimulus, "stimulus2", "stimulus1")) # ensure that factor levels are the in the correct order, especially for d_b

# faux also has rnorm_multi which can simulate these stimulus correlations, but it can't do the multiple outcome measures. 
# to do both, a more complex simulation would be needed. I don't think this is needed for testing.
# faux::rnorm_multi(n = 100,
#                     mu = c(stimulus1 = 0, stimulus2 = 0.2),
#                     sd = c(1, 1),
#                     r = matrix(c( 1.0, -0.7,
#                                   -0.7,  1.0),
#                                ncol = 2)) |>
#   rownames_to_column(var = "id") 

dat_checks <-
  # this chunk is run just to generate ID codes of the same format. only the IDs are then retained.
  sim_design(within = list(measure = c(original = 'original',
                                         new1 = 'refined scale 1 - based on loadings with single item desirability',
                                         new2 = 'refined scale 2 - based on main factor of original scale',
                                         classic = 'classic items used in evaluative learning studies',
                                         single = 'single item desirability')),
               between = list(condition = c(stimulus1 = 'stimulus1',
                                            stimulus2 = 'stimulus2')),
               n  = 100, 
               mu = 0.8, 
               sd = 1.0,
               r  = 0.80, 
               dv = "stimulus2",
               long = TRUE,
               plot = FALSE) |>
      mutate(id = as.factor(id)) |>
      arrange(id) |>
  distinct(id) |>
  # attention checks etc
  mutate(self_exclude                = rbinom(n = n(), size = 1, prob = 0.9),  # assumes 1 = check passed 
         attention_check_1           = rbinom(n = n(), size = 1, prob = 0.9),
         attention_check_2           = rbinom(n = n(), size = 1, prob = 0.9),
         bot_check                   = rbinom(n = n(), size = 1, prob = 0.9),
         total_completion_check      = rbinom(n = n(), size = 1, prob = 0.9),
         iter_item_agreement_check_1 = rbinom(n = n(), size = 1, prob = 0.9),
         iter_item_agreement_check_2 = rbinom(n = n(), size = 1, prob = 0.9)) |>
  rowwise() |>
  mutate(three_or_more_checks_failed = ifelse(attention_check_1 + attention_check_2 + bot_check + total_completion_check + iter_item_agreement_check_1 + iter_item_agreement_check_2 < 4, "failed", "passed"),
         two_or_more_checks_failed = ifelse(attention_check_1 + attention_check_2 + bot_check + total_completion_check + iter_item_agreement_check_1 + iter_item_agreement_check_2 < 5, "failed", "passed"),
         any_checks_failed = ifelse(attention_check_1 + attention_check_2 + bot_check + total_completion_check + iter_item_agreement_check_1 + iter_item_agreement_check_2 < 6, "failed", "passed")) |>
  ungroup() |>
  mutate(self_exclude = ifelse(as.logical(self_exclude), "passed", "failed"),
         attention_check_1 = ifelse(as.logical(attention_check_1), "passed", "failed"),
         attention_check_2 = ifelse(as.logical(attention_check_2), "passed", "failed"),
         bot_check = ifelse(as.logical(bot_check), "passed", "failed"),
         total_completion_check = ifelse(as.logical(total_completion_check), "passed", "failed"),
         iter_item_agreement_check_1 = ifelse(as.logical(iter_item_agreement_check_1), "passed", "failed"),
         iter_item_agreement_check_2 = ifelse(as.logical(iter_item_agreement_check_2), "passed", "exclude"))

dat_combined <- left_join(dat_outcomes, dat_checks, by = "id")

```

# Run multiverse

\TODO still to figure out how to apply map the above function onto the same data frame using different exclusions, and for each outcome measure. 

filter by outcome, as a variable, and excluding using {{check}}; put both in an expand grid?

```{r}

conditions <- expand_grid(
  measure = c("original",
              "new1",
              "new2",
              "classic",
              "single"),
  check = c("self_exclude",
            "attention_check_1", 
            "attention_check_2", 
            "bot_check", 
            "total_completion_check", 
            "iter_item_agreement_check_1", 
            "iter_item_agreement_check_2", 
            "three_or_more_checks_failed", 
            "two_or_more_checks_failed", 
            "any_checks_failed")
) |>
  bind_cols(nest(dat_combined))

library(purrr)

multiverse_results <- conditions |>
  mutate(results = pmap(list(data,
                             measure,
                             check),
                        multiverse_analysis))

write_rds(multiverse_results, "multiverse_results.rds")
multiverse_results <- read_rds("multiverse_results.rds")


```

The rm standardized difference requires paired data,
  but data contains more than one observation per design cell.
  Aggregating data using `mean()`.
The av standardized difference requires paired data,
  but data contains more than one observation per design cell.
  Aggregating data using `mean()`.
The b standardized difference requires paired data,
  but data contains more than one observation per design cell.
  Aggregating data using `mean()`.
The b standardized difference requires paired data,
  but data contains more than one observation per design cell.
  Aggregating data using `mean()`.
The z standardized difference requires paired data,
  but data contains more than one observation per design cell.
  Aggregating data using `mean()`.

```{r fig.height=8, fig.width=8}

# dependencies
library(tidyr)
library(dplyr)
library(purrr) 
library(ggplot2)
library(ggtext)
library(janitor)


multiverse_plot <- function(data, 
                            outcome = "outcome", 
                            outcome_name = "Outcome",
                            interval_lower = NULL,
                            interval_upper = NULL,
                            rank_by = "rank",
                            rank_by_outcome = FALSE,
                            relative_height_of_upper_plot = 0.70, 
                            outcome_cutoff = NULL){
  
  # dependencies
  require(dplyr)
  require(tidyr)
  require(ggplot2)
  require(cowplot)

  # TODO consider checking inputs with rlang::ensym(variable)

  # rename outcome variable
  data <- data |>
    rename(outcome = {{outcome}},
           rank = {{rank_by}})
  
  # if intervals aren't specified, set them to the same value as outcome (so they are invisible in the plot)
  if(!is.null(interval_lower)){
    data <- data |>
      rename(interval_lower = {{interval_lower}})
  } else {
    data$interval_lower <- data$outcome
  }
  
  if(!is.null(interval_upper)){
    data <- data |>
      rename(interval_upper = {{interval_upper}})
  } else {
    data$interval_upper <- data$outcome
  }
  
  # if rank_by_outcome, rank by the outcome. otherwise, take order that was passed.
  if(rank_by_outcome){
    data <- data |>
      arrange(outcome) |>
      mutate(rank = row_number())
  }
  
  # ensure all columns other than rank and outcome are factors
  data <- data |>
    mutate(across(.cols = -c(rank, outcome, interval_lower, interval_upper),
                  .fns = as.factor))
  
  p_estimates <- data |>
    mutate(outcome_name = outcome_name) |>
    ggplot(aes(rank, outcome)) +
    geom_linerange(aes(ymin = interval_lower, ymax = interval_upper), alpha = 0.2) +
    geom_point(shape = 20, size = 1) +
    facet_grid(outcome_name ~ ., space = "free_y", scales = "free_y", switch = "y") +
    scale_y_continuous(breaks = scales::pretty_breaks()) + 
    scale_x_continuous(NULL, expand = c(.02, .02)) +
    ylab("Results") +
    #theme_classic() +
    theme_minimal() +
    theme(legend.position = "none",
          axis.line.x = element_blank(),
          strip.placement = "outside",
          strip.background = element_rect(fill = NA, colour = NA),
          panel.spacing.x = unit(0.15, "cm"),
          strip.text.y = element_markdown(angle = 180, face = "bold", size = 7),
          axis.text.y = element_text(angle = 0, 
                                     hjust = 0.5, 
                                     size = 6),
          axis.title.y = element_text(size = 9, face = "bold"),
          panel.spacing = unit(0.25, "lines"),
          axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
  
  if(!is.null(outcome_cutoff)){
    p_estimates <- p_estimates + geom_hline(yintercept = outcome_cutoff, linetype = "dotted")
  }
  
  p_specs <- data |> 
    tidyr::pivot_longer(cols = c(-"rank", -"outcome", -"interval_lower", -"interval_upper")) |> 
    arrange(rank) |>
    ggplot(aes(x = rank, y = factor(value), color = name)) + 
    geom_point(shape = 124, size = 1) +
    facet_grid(name ~ ., space = "free_y", scales = "free_y", switch = "y") +
    guides(color = "none") +
    scale_x_continuous(NULL, expand = c(.02, .02)) +
    ylab("Specification") +
    #theme_classic() +
    theme_minimal() +
    theme(strip.placement = "outside",
          strip.background = element_rect(fill = NA, colour = NA),
          panel.spacing.x = unit(0.15, "cm"),
          strip.text.y = element_markdown(angle = 180, face = "bold", size = 7),
          axis.text.y = element_text(angle = 0, hjust = 1, size = 6),
          axis.title.y = element_text(size = 9, face = "bold"),
          panel.spacing = unit(0.25, "lines"),
          axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank()) +
    scale_color_brewer(palette = "Dark2")

  p_multiverse <- cowplot::plot_grid(p_estimates, 
                                     p_specs, 
                                     axis = "bltr", 
                                     align = "v", 
                                     ncol = 1, 
                                     rel_heights = c(relative_height_of_upper_plot, 1))
  
  return(p_multiverse)
}


multiverse_summary <- multiverse_results |>
  select(-data) |>
  unnest(results) |>
  select(Measure = measure, Exclusions = check, Implementation = implementation, Version = type, outcome = estimate, ci_lower, ci_upper) |>
  mutate(Type = case_when(Version == "d_b (alt)" ~ "Dependent",
                          Version == "d_av" ~ "Dependent",
                          Version == "d_rm" ~ "Dependent",
                          Version == "d_b" ~ "Dependent",
                          Version == "d_s" ~ "Independent",
                          Version == "d_t (independent)" ~ "Independent",
                          Version == "d_s_withinCIs" ~ "Dependent",
                          Version == "d_??? (indep)" ~ "Independent",
                          Version == "d_??? (dep)" ~ "Dependent",
                          Version == "d_z" ~ "Dependent",
                          Version == "d_t (dependent, r = 0)" ~ "Dependent")) |>
  mutate(Exclusions = case_match(Exclusions,
                            "self_exclude" ~ "Self-exclude",
                            "attention_check_1" ~ "Attention check 1", 
                            "attention_check_2" ~ "Attention check 2", 
                            "bot_check" ~ "Bot check", 
                            "total_completion_check" ~ "Completion time", 
                            "iter_item_agreement_check_1" ~ "Inter-item 1", 
                            "iter_item_agreement_check_2" ~ "Inter-item 2", 
                            "three_or_more_checks_failed" ~ "3+ failed", 
                            "two_or_more_checks_failed" ~ "2+ failed", 
                            "any_checks_failed" ~ "Any failed")) |>
  arrange(outcome) |>
  mutate(rank = row_number())
  

p_multiverse <- 
  multiverse_plot(multiverse_summary, 
                  outcome_name = "Cohen's d",
                  outcome_cutoff = 0,
                  interval_lower = "ci_lower",
                  interval_upper = "ci_upper")

p_multiverse

```

# Session info

```{r}

sessionInfo()

```

